{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d878fab",
   "metadata": {},
   "source": [
    "<h1 style=\"color: blue;\">라. Ensemble 앙상블 기법</h1>\n",
    "\n",
    "**앙상블 기법은 여러 개의 개별 모델을 결합하여 더 강력한 예측 모델을 만드는 머신러닝 기법입니다. 개별 모델은 독립적으로 학습하고 예측을 수행한 후, 그 결과를 조합하여 최종 예측을 수행합니다.**\n",
    "\n",
    "### 앙상블 기법의 주요 이점\n",
    "\n",
    "+ 성능 향상 : 앙상블 기법은 여러 개의 다양한 모델을 결합함으로써 예측 성능을 향상시킬 수 있습니다. 각 모델이 독립적으로 학습되기 때문에, 앙상블은 개별 모델보다 더욱 강력한 일반화 능력을 가질 수 있습니다.\n",
    "<br></br>\n",
    "+ 과적합 감소 : 앙상블은 개별 모델의 경향성을 상쇄시켜 과적합을 감소시킵니다. 다양한 모델을 결합 하면서 각 모델의 과적합이 상호 보완되기 때문에, 더 안정적이고 일반화 능력이 높은 모델을 얻을 수 있습니다.\n",
    "<br></br>\n",
    "+ 신뢰성 향상 : 앙상블은 다양한 모델의 예측 결과를 조합함으로써 예측의 신뢰성을 향상시킵니다. 여 러 모델의 다양성을 활용하면서 앙상블은 더욱 견고하고 신뢰할 수 있는 예측을 제공할 수 있습니다.\n",
    "<br></br>\n",
    "+ 다양성 확보 : 앙상블은 다양한 모델을 결합하기 때문에, 각 모델이 다른 특징을 학습하고 다양한 정보를 제공할 수 있습니다. 이는 데이터의 다양성을 높여서 예측의 다양한 측면을 고려할 수 있도록 도와 줍니다.\n",
    "<br></br>\n",
    "+ 대규모 데이터 학습의 효율성 : 앙상블은 개별 모델을 독립적으로 학습하고 예측하기 때문에, 대규모 데이터셋을 활용하여 분산 학습과 예측을 수행할 수 있습니다. 이는 학습 시간을 단축하고 효율성을 향 상시킬 수 있습니다.\n",
    "\n",
    "<h2 style=\"color: green;\">앙상블 기법 - 배깅</h2>\n",
    "\n",
    "앙상블 기법은 여러 개의 개별 모델을 결합하여 더 강력한 예측 모델을 만드는 머신러닝 기법입니다. 개별 모델은 독립적으로 학습하고 예측을 수행한 후, 그 결과를 조합하여 최종 예측을 수행합니다.\n",
    "\n",
    "### 앙상블 기법의 주요 이점\n",
    "\n",
    "+ 성능 향상 : 앙상블 기법은 여러 개의 다양한 모델을 결합함으로써 예측 성능을 향상시킬 수 있습니다. 각 모델이 독립적으로 학습되기 때문에, 앙상블은 개별 모델보다 더욱 강력한 일반화 능력을 가질 수 있습니다.\n",
    "<br></br>\n",
    "+ 과적합 감소 : 앙상블은 개별 모델의 경향성을 상쇄시켜 과적합을 감소시킵니다. 다양한 모델을 결합 하면서 각 모델의 과적합이 상호 보완되기 때문에, 더 안정적이고 일반화 능력이 높은 모델을 얻을 수 있습니다.\n",
    "<br></br>\n",
    "+ 신뢰성 향상 : 앙상블은 다양한 모델의 예측 결과를 조합함으로써 예측의 신뢰성을 향상시킵니다. 여 러 모델의 다양성을 활용하면서 앙상블은 더욱 견고하고 신뢰할 수 있는 예측을 제공할 수 있습니다.\n",
    "<br></br>\n",
    "+ 다양성 확보 : 앙상블은 다양한 모델을 결합하기 때문에, 각 모델이 다른 특징을 학습하고 다양한 정보를 제공할 수 있습니다. 이는 데이터의 다양성을 높여서 예측의 다양한 측면을 고려할 수 있도록 도와 줍니다.\n",
    "<br></br>\n",
    "+ 대규모 데이터 학습의 효율성 : 앙상블은 개별 모델을 독립적으로 학습하고 예측하기 때문에, 대규모 데이터셋을 활용하여 분산 학습과 예측을 수행할 수 있습니다. 이는 학습 시간을 단축하고 효율성을 향 상시킬 수 있습니다.\n",
    "\n",
    "<h2 style=\"color: green;\">앙상블 기법 - 배깅</h2>\n",
    "\n",
    "배깅은 Bootstrap Aggregating의 약자로, 데이터셋을 중복 추출하여 각각의 데이터로 개별 모델을 학습시키는 기법입니다. **복원 추출은 데이터를 선택할 때 중복을 허용하는 방식**\n",
    "\n",
    "개별 모델은 독립적으로 학습되고 예측을 수행한 후, 예측 결과를 평균 또는 투표를 통해 결합하여 최종 예측을 수행합니다.\n",
    "\n",
    "대표적인 알고리즘으로는 랜덤 포레스트(Random Forest)가 있습니다.\n",
    "\n",
    "### 배깅의 동작 방식\n",
    "\n",
    "+ 재샘플링 : 원본 데이터셋에서 무작위로 복원 추출을 통해 새로운 훈련 데이터셋을 생성합니다. 이 로 인해 원본 데이터셋의 크기와 동일하게 되지만, 일부 데이터는 중복되거나 누락될 수 있습니다. 이 과정을 여러 번 반복하여 서로 다른 훈련 데이터셋을 생성합니다.\n",
    "<br></br>\n",
    "+ 독립적인 모델 훈련 : 각각의 재샘플링된 훈련 데이터셋에 대해 독립적인 모델을 훈련합니다. 예를 들어, 재샘플링된 데이터셋에서 복원 추출된 훈련 데이터를 사용하여 모델을 학습합니다.\n",
    "<br></br>\n",
    "+ 모델 앙상블 : 훈련된 모델들을 앙상블합니다. 분류 문제의 경우, 앙상블은 다수결 투표를 사용하여 예측 결과를 결정합니다. 회귀 문제의 경우, 앙상블은 모든 모델의 예측 값을 평균하여 최종 예측을 얻습니다.\n",
    "\n",
    "### 배깅의 이점\n",
    "\n",
    "+ 분산 감소 : 다양한 모델을 독립적으로 훈련하고 앙상블하므로 모델의 분산을 감소시킵니다. 이는 일반화 성능을 향상시킵니다.\n",
    "<br></br>\n",
    "+ 과적합 감소 : 재샘플링을 통해 생성된 다양한 훈련 데이터셋은 모델이 다양한 샘플에 대해 학습하도록 도움을 줍니다. 이는 과적합을 감소시키는 효과가 있습니다.\n",
    "<br></br>\n",
    "+ 예측 성능 향상 :다수의 모델을 앙상블하여 예측을 결합하면 개별 모델보다 더 좋은 예측 성능을 얻을 수 있습니다.\n",
    "\n",
    "## *PyTorch 앙상블 기법 실습 - 배깅*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeaf300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d354778",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "264a4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super(CNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "        nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        \n",
    "        nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(32 * 8 * 8, 10)\n",
    "\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #배치사이즈 기준으로 평탄화\n",
    "        \"\"\"\n",
    "        예를 들어, x 텐서의 크기가 (2, 3, 4)인 경우, x = x.view(x.size(0), -1)를 실행하면 \n",
    "        x 텐서는 (2, 12)의 크기로 변경됩니다. 첫 번째 차원은 그대로 유지되고, \n",
    "        두 번째 차원은 원래의 차원 크기들을 곱한 값인 12로 조정됩니다.\n",
    "        \"\"\"\n",
    "        #배치 사이즈를 고려하여 배치 사이즈별로 이미지를 1차원으로 flatten한다.\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08831697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.3,0.3,0.3))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.3,0.3,0.3))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='../../data', train=True, download=True, transform=train_transform)\n",
    "test_dataset = datasets.CIFAR10(root='../../data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cde7682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an ensemble of CNN model\n",
    "num_models = 5\n",
    "models = [CNN().to(device) for _ in range(num_models)]\n",
    "\n",
    "# Define loss function and optimizer \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizers = [optim.AdamW(model.parameters(), lr=0.001) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "304b6a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, ACC 0.5438\n",
      "Epoch 2/2, ACC 0.593\n"
     ]
    }
   ],
   "source": [
    "#생성된 모델 5개에 각각 2번의 에포크 단위로 학습 -> 총 10번의 학습\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs) : \n",
    "    for model, optimizer in zip(models, optimizers) : \n",
    "        model.train()\n",
    "        for images, labels in train_loader : \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    # Evaluation after each epoch \n",
    "    for model in models : \n",
    "        model.eval()\n",
    "        \n",
    "    predictions = []\n",
    "    targets = []\n",
    "    with torch.no_grad() : \n",
    "        for images, labels in test_loader : \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            ensemble_outputs = torch.zeros((images.size(0), 10)).to(device)\n",
    "            for model in models : \n",
    "                outputs = model(images)\n",
    "                ensemble_outputs += outputs/num_models\n",
    "                #outputs는 num_models로 나누어져 각 모델의 예측이 동등한 비중으로 반영됩니다. 이렇게 함으로써 앙상블의 결과로 최종 예측이 결정됩니다.\n",
    "                #각 모델의 가중치를 1/5로 함으로써 모델 총 개수 5번을 돌려야 완성된다.\n",
    "                _, pred = torch.max(ensemble_outputs.data, 1)\n",
    "\n",
    "            predictions.extend(pred.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            #pred와 labels는 GPU 메모리에 있는 텐서일 수 있으므로, .cpu()를 사용하여 CPU로 옮겨주는 작업을 수행\n",
    "            \n",
    "    acc = accuracy_score(targets, predictions)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, ACC {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e71615",
   "metadata": {},
   "source": [
    "### 배깅 투표 방식\n",
    "\n",
    "**PyTorch를 사용하여 배깅을 CNN에 적용한 실습 - 앙상블 모델을 사용할 때는 각 개별 모델을 학습한 후 앙상블 모델의 최종 예측을 위해서 개별 모델의 예측을 결합**\n",
    "\n",
    "+ 투표 방식은 개별 모델의 예측 결과 중 가장 많은 표를 받은 클래스를 최종 예측으로 선택하는 방식입니다. 예를 들어, 5개의 모델 중 3개가 클래스 A를 예측하고 2개가 클래스 B를 예측했다면, 투표 결과로 클래스 A를 선택합니다.\n",
    "<br></br>\n",
    "+ 평균화 방식은 개별 모델의 예측 확률을 평균 계산하여 최종 예측 확률을 계산하는 방식입니다. 예를들어, 5개의 모델이 각각 클래스 A의 예측 확률을 [0.8, 0.7, 0.9, 0.6, 0.8]로 예측했다면, 이를 평균하여 최종 예측 확률을 [0.76]로 계산합니다. 이후, 가장 높은 확률을 가진 클래스를 최종 예측으로 선택합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
