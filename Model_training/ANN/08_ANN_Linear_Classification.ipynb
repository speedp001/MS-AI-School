{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "328cc9eb",
   "metadata": {},
   "source": [
    "## 선형 분류 - 퍼셉트론 (Perceptron)\n",
    "\n",
    "### 퍼셉트론이란?\n",
    "\n",
    "퍼셉트론(Perceptron)은 인공신경망(ANN)의 한 종류로, 이진 분류 문제를 해결하는 데 사용됩니다. 이진 분류는 두 가지 범주 중 하나에 데이터 포인트를 할당하는 작업입니다. 이론적으로 퍼셉트론은 하나 이상의 입력 값을 받아서 하나의 출력값을 생성합니다.\n",
    "\n",
    "퍼셉트론은 초기 인공지능 분야의 발전을 이끈 프랑크 로젠블라트(Frank Rosenblatt)가 1957년에 개발했습니다. 이후, 퍼셉트론은 인공신경망의 핵심 구성 요소로 남았습니다. 퍼셉트론은 머신 러닝에서 지도 학습(Supervised Learning)을 수행하는 알고리즘 중 하나입니다. 지도 학습은 입력 데이터와 해당 데이터의 정답(라벨)을 모두 제공하여 학습을 진행하는 방식입니다.\n",
    "\n",
    "퍼셉트론은 입력 데이터를 받아 가중치를 곱하고 편향을 더한 값을 출력으로 계산합니다. 출력 값은 미리 설정한 임계치를 기준으로 0 또는 1로 변환됩니다. 이러한 퍼셉트론은 선형 분류 문제에서 사용할 수 있습니다. 퍼셉트론은 다양한 문제를 해결하는 데 사용됩니다. 예를 들어, 스팸 메일 필터링, 패턴 인식, 이미지 분류 등이 그 예입니다.\n",
    "\n",
    "### 동작 원리\n",
    "\n",
    "퍼셉트론은 입력 신호를 받아 가중치와 곱한 값을 모두 더한 뒤, 그 값이 임계치(threshold)를 넘으면 1을 출력하고, 넘지 않으면 0을 출력하는 이진 분류 모델입니다. 즉,입력 신호와 가중치의 곱의 합이 임계치를 넘으면 양성 클래스(1)에 속하고, 그렇지 않으면 음성 클래스(0)에 속하는 것으로 결정됩니다.\n",
    "\n",
    "퍼셉트론은 초기에는 가중치를 무작위로 초기화하고, 입력 데이터를 하나씩 주입하여 결과를 출력합니다. 그 결과를 바탕으로 오차를 계산하여 가중치를 조정합니다. 이 과정을 반복하면서 가중치를 최적화시키고, 입력 데이터를 정확하게 분류할 수 있도록 합니다. 이러한 학습 과정을 퍼셉트론 학습 규칙(Perceptron Learning Rule)이라고 합니다.\n",
    "\n",
    "퍼셉트론은 하나의 층으로 이루어진 단층 퍼셉트론과 여러 개의 층으로 이루어진 다층 퍼셉트론으로 나눌 수 있습니다. 단층 퍼셉트론은 선형 분리 가능한 문제에 대해서만 사용할 수 있으며, XOR과 같이 비선형 문제를 해결할 수 없습니다. 따라서 다층 퍼셉트론을 사용하여 비선형 분류 문제를 해결할 수 있습니다.\n",
    "\n",
    "### 퍼셉트론 학습 알고리즘의 개념\n",
    "\n",
    "퍼셉트론 학습 알고리즘은 지도 학습(Supervised Learning) 방법 중 하나로, 데이터의 특징(feature)과 레이 블(label)이 주어졌을 때 이를 기반으로 모델의 가중치(weight)를 업데이트하여 최적의 모델을 학습하는 알고리즘입니다.\n",
    "\n",
    "**1. 초기화:** 가중치 w와 편향 b를 0 혹은 랜덤한 값으로 초기화합니다.\n",
    "<br></br>\n",
    "**2. 학습 데이터 가져오기:** 학습에 필요한 데이터를 가져옵니다.\n",
    "<br></br>\n",
    "**3. 예측값 계산:** 가져온 데이터의 특징과 가중치를 곱한 값을 더한 후, 편향을 더하여 예측값을 계산합니다. 계산된 예측값이 0보다 크면 1,0보다 작으면 -1로 분류합니다.\n",
    "<br></br>\n",
    "**4. 가중치 업데이트:** 계산된 예측값과 실제 레이블의 차이를 구합니다. 이 차이를 이용하여 가중치와 편향을 업데이트합니다. 예를들어, 실제 레이블이 1이지만 예측값이 -1일 경우, 가중치 w와 편향 b를 다음과 같이 업데이트합니다. \n",
    "\n",
    "- w = w + learning_rate * x\n",
    "- b = b + learning_rate * 1\n",
    "<br></br>\n",
    "\n",
    "**5. 모든 데이터에 대해 반복:** 위의 과정을 모든 데이터에 대해 반복합니다. 반복 횟수나 에포트는 사용자가 지정합니다.\n",
    "<br></br>\n",
    "**6. 예측:** 학습된 모델을 이용하여 새로운 데이터의 레이블을 예측합니다.\n",
    "<br></br>\n",
    "\n",
    "### 퍼셉트론 학습 알고리즘의 한계\n",
    "\n",
    "단층 퍼셉트론은 선형 분리 문제만 해결할 수 있기 때문에, 비선형 분리 문제에 대해서는 제대로 동작하지 않습니다. 또한, 퍼셉트론 학습 알고리즘에서는 분류 오류를 줄이는 가중치 조정을 반복적으로 수행하면서 최적의 가중치 값을 찾아야 하는데, 이 과정에서 학습 데이터에 대해 수렴하지 않는 경우가 있습니다.\n",
    "\n",
    "## *퍼셉트론 실습*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2f6244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 훈련 데이터\n",
    "x = torch.Tensor([[0,0], [0,1], [1,0], [1,1]])\n",
    "y = torch.Tensor([[0], [0], [1]])\n",
    "\n",
    "# 모델 초기화\n",
    "w = torch.randn(2, 1, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "lr = 0.1\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c530010e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ddddac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1312bdd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc98cc72",
   "metadata": {},
   "source": [
    "### 다중 층 퍼셉트론(multilayer perceptron)의 필요성\n",
    "\n",
    "다중 층 퍼셉트론(multilayer perceptron)은 여러 개의 은닉층(hidden layer)을 추가하여 비선형 문제에 대한 해결이 가능하도록 하였습니다. 은닉층을 추가하면서 입력 데이터를 비선형으로 변환하는 함수를 사용하여 다양한 패턴을 학습할 수 있습니다. 또한, 역전파 알고리즘을 이용하여 학습하면 더욱 정확한 분류 모델을 만들 수 있습니다. 따라서, 다중 층 퍼셉트론은 단층 퍼셉트론의 한계를 극복하고, 보다 복잡한 문제에 대한 해결이 가능하도록 하였습니다.\n",
    "\n",
    "## *다중 층 퍼셉트론 실습*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0574c7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# 학습 데이터 로딩\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=64, shuffle=True)\n",
    "\n",
    "# 테스트 데이터 로딩\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28088be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.117\n",
      "[1,   200] loss: 1.439\n",
      "[1,   300] loss: 0.840\n",
      "[1,   400] loss: 0.582\n",
      "[1,   500] loss: 0.502\n",
      "[1,   600] loss: 0.442\n",
      "[1,   700] loss: 0.406\n",
      "[1,   800] loss: 0.384\n",
      "[1,   900] loss: 0.365\n",
      "[2,   100] loss: 0.367\n",
      "[2,   200] loss: 0.344\n",
      "[2,   300] loss: 0.304\n",
      "[2,   400] loss: 0.317\n",
      "[2,   500] loss: 0.305\n",
      "[2,   600] loss: 0.292\n",
      "[2,   700] loss: 0.288\n",
      "[2,   800] loss: 0.278\n",
      "[2,   900] loss: 0.293\n",
      "[3,   100] loss: 0.267\n",
      "[3,   200] loss: 0.271\n",
      "[3,   300] loss: 0.253\n",
      "[3,   400] loss: 0.267\n",
      "[3,   500] loss: 0.245\n",
      "[3,   600] loss: 0.260\n",
      "[3,   700] loss: 0.244\n",
      "[3,   800] loss: 0.240\n",
      "[3,   900] loss: 0.239\n",
      "[4,   100] loss: 0.230\n",
      "[4,   200] loss: 0.230\n",
      "[4,   300] loss: 0.234\n",
      "[4,   400] loss: 0.213\n",
      "[4,   500] loss: 0.228\n",
      "[4,   600] loss: 0.200\n",
      "[4,   700] loss: 0.220\n",
      "[4,   800] loss: 0.202\n",
      "[4,   900] loss: 0.189\n",
      "[5,   100] loss: 0.201\n",
      "[5,   200] loss: 0.195\n",
      "[5,   300] loss: 0.204\n",
      "[5,   400] loss: 0.168\n",
      "[5,   500] loss: 0.188\n",
      "[5,   600] loss: 0.182\n",
      "[5,   700] loss: 0.177\n",
      "[5,   800] loss: 0.170\n",
      "[5,   900] loss: 0.189\n",
      "[6,   100] loss: 0.167\n",
      "[6,   200] loss: 0.174\n",
      "[6,   300] loss: 0.166\n",
      "[6,   400] loss: 0.161\n",
      "[6,   500] loss: 0.166\n",
      "[6,   600] loss: 0.159\n",
      "[6,   700] loss: 0.161\n",
      "[6,   800] loss: 0.159\n",
      "[6,   900] loss: 0.152\n",
      "[7,   100] loss: 0.152\n",
      "[7,   200] loss: 0.151\n",
      "[7,   300] loss: 0.148\n",
      "[7,   400] loss: 0.141\n",
      "[7,   500] loss: 0.147\n",
      "[7,   600] loss: 0.138\n",
      "[7,   700] loss: 0.138\n",
      "[7,   800] loss: 0.139\n",
      "[7,   900] loss: 0.143\n",
      "[8,   100] loss: 0.137\n",
      "[8,   200] loss: 0.141\n",
      "[8,   300] loss: 0.128\n",
      "[8,   400] loss: 0.123\n",
      "[8,   500] loss: 0.121\n",
      "[8,   600] loss: 0.127\n",
      "[8,   700] loss: 0.126\n",
      "[8,   800] loss: 0.132\n",
      "[8,   900] loss: 0.127\n",
      "[9,   100] loss: 0.120\n",
      "[9,   200] loss: 0.123\n",
      "[9,   300] loss: 0.109\n",
      "[9,   400] loss: 0.118\n",
      "[9,   500] loss: 0.116\n",
      "[9,   600] loss: 0.114\n",
      "[9,   700] loss: 0.114\n",
      "[9,   800] loss: 0.116\n",
      "[9,   900] loss: 0.123\n",
      "[10,   100] loss: 0.107\n",
      "[10,   200] loss: 0.108\n",
      "[10,   300] loss: 0.100\n",
      "[10,   400] loss: 0.111\n",
      "[10,   500] loss: 0.106\n",
      "[10,   600] loss: 0.109\n",
      "[10,   700] loss: 0.103\n",
      "[10,   800] loss: 0.101\n",
      "[10,   900] loss: 0.107\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x)) \n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "model = MLP()\n",
    "\n",
    "#손실함수 및 최적화 알고리즘 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "# 학습 실행\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i+1, running_loss / 100))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc75e3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96 %\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12221d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610d9072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
