{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "626a0719",
   "metadata": {},
   "source": [
    "<h2 style=\"color: green;\">텍스트 데이터 처리</h2>\n",
    "\n",
    "## 구두점 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d59f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fde1e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#텍스트 정제\n",
    "text_data = [\" import re 모듈은 파이썬에서 정규 표현식을 사용하기 위해 제공되는 내장 모듈입니다. ???\",\n",
    "            \"정규 표현식은 문자열 패턴을 검색, 추출, 대체 또는 분할하는데 사용됩니다. !!!!! \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b3f44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['import re 모듈은 파이썬에서 정규 표현식을 사용하기 위해 제공되는 내장 모듈입니다. ???', '정규 표현식은 문자열 패턴을 검색, 추출, 대체 또는 분할하는데 사용됩니다. !!!!!']\n"
     ]
    }
   ],
   "source": [
    "#공백 문자 제거\n",
    "strip_whitespace = [string.strip() for string in text_data]  #공백 문자 제거\n",
    "\n",
    "print(strip_whitespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fccee72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['import re 모듈은 파이썬에서 정규 표현식을 사용하기 위해 제공되는 내장 모듈입니다 ???', '정규 표현식은 문자열 패턴을 검색, 추출, 대체 또는 분할하는데 사용됩니다 !!!!!']\n"
     ]
    }
   ],
   "source": [
    "#마침표 제거\n",
    "remove_periods = [string.replace(\".\",\"\") for string in strip_whitespace]\n",
    "print(remove_periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aa0cdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' import re 모듈은 파이썬에서 정규 표현식을 사용하기 위해 제공되는 내장 모듈입니다 ', '정규 표현식은 문자열 패턴을 검색 추출 대체 또는 분할하는데 사용됩니다  ']\n"
     ]
    }
   ],
   "source": [
    "#구두점 삭제\n",
    "import sys\n",
    "import unicodedata\n",
    "\n",
    "temp = dict.fromkeys(i for i in range(sys.maxunicode) if unicodedata.category(chr(i)).startswith('P'))\n",
    "\n",
    "data = [string.translate(temp) for string in text_data]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dafbe1",
   "metadata": {},
   "source": [
    "## 텍스트 토큰화\n",
    "+ 텍스트를 개별 단어로 나눕니다.\n",
    "+ 자연어 처리 툴킷인 NLTK는 단어 토큰화를 비롯해 강력한 텍스트 처리 기능을 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7979b6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99a94fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sang-yun/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#구두점 데이터 다운로드\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4a34b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['모듈은', '정규', '표현식을', '사용하여', '문자열에서', '패턴을', '찾고', '조작하는', '데', '사용되는', '파이썬', '내장', '모듈입니다', '.']\n"
     ]
    }
   ],
   "source": [
    "string = \"모듈은 정규 표현식을 사용하여 문자열에서 패턴을 찾고 조작하는 데 사용되는 파이썬 내장 모듈입니다.\"\n",
    "\n",
    "word_data = word_tokenize(string)  #단어를 토큰 기준으로 나눕니다.\n",
    "print(word_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "402f5953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['안녕하세요, 문장을 구분하는 명령어 예시입니다.', '안녕하세요, 문장을 구분하는 명령어 예시입니다.']\n"
     ]
    }
   ],
   "source": [
    "sent_string = \"안녕하세요, 문장을 구분하는 명령어 예시입니다. 안녕하세요, 문장을 구분하는 명령어 예시입니다.\"\n",
    "sent_data = sent_tokenize(sent_string)\n",
    "print(sent_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28b13fb",
   "metadata": {},
   "source": [
    "## 불용어 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ae2eaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/sang-\n",
      "[nltk_data]     yun/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')  #불용어 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "781d7159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['going', 'go', 'store', 'park']\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "tokenized_words = ['i', 'am', 'going', 'to', 'go', 'to', 'the', 'store', 'and', 'park']\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "#불용어 삭제 -> 기존에 불용어로 인식된 단어들을 삭제\n",
    "filtered_words = [word for word in tokenized_words if word not in stop_words]\n",
    "print(filtered_words)\n",
    "\n",
    "#불용어 확인 -> 불용어라고 인식되는 단어들\n",
    "stop_data = stop_words\n",
    "print(stop_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6354b2f3",
   "metadata": {},
   "source": [
    "## 어간 추출\n",
    "\n",
    "단어의 어간을 구분하여 기본 의미를 유지하면서 어미를 제거한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49114260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a81d398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "am\n",
      "going\n",
      "to\n",
      "go\n",
      "to\n",
      "the\n",
      "store\n",
      "and\n",
      "meeting\n",
      "['i', 'am', 'go', 'to', 'go', 'to', 'the', 'store', 'and', 'meet']\n"
     ]
    }
   ],
   "source": [
    "tokenized_words_temp = ['i', 'am', 'going', 'to', 'go', 'to', 'the', 'store', 'and', 'meeting']\n",
    "\n",
    "#어간 추출기 생성\n",
    "porter = PorterStemmer()\n",
    "word_list_temp = []\n",
    "for word in tokenized_words_temp :\n",
    "    print(word)\n",
    "    word_list_temp.append(porter.stem(word))\n",
    "    \n",
    "print(word_list_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9513f2b",
   "metadata": {},
   "source": [
    "## 품사 태깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9a5daa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2975adc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sang-yun/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cacd1023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Chris', 'NNP'), ('loved', 'VBD'), ('outdoor', 'RP'), ('running', 'VBG')]\n"
     ]
    }
   ],
   "source": [
    "text_data_tag = \"Chris loved outdoor running\"\n",
    "text_tagger = pos_tag(word_tokenize(text_data_tag))\n",
    "print(text_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ee4b0b",
   "metadata": {},
   "source": [
    "## 단어 중요도에 가중치 부여하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a85abddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c71b2bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'love': 6, 'brazil': 3, 'swedn': 7, 'is': 5, 'best': 1, 'germany': 4, 'beats': 0, 'both': 2}\n"
     ]
    }
   ],
   "source": [
    "text_data_01 = np.array([\n",
    "    \"I love Brazil.Brazil !\",\n",
    "    \"Swedn is best\",\n",
    "    \"Germany is beats both\"\n",
    "])\n",
    "\n",
    "#tf-idr 특성 행렬\n",
    "tfidf = TfidfVectorizer()\n",
    "feature_matrix = tfidf.fit_transform(text_data_01)\n",
    "\n",
    "#tf-idr 특성 행렬을 밀집 배열 확인\n",
    "feature_matrix.toarray()\n",
    "tf = tfidf.vocabulary_\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe57b98c",
   "metadata": {},
   "source": [
    "## Word Cloud 단어 뭉치를 가시화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "594f08f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytagcloud in /Users/sang-yun/anaconda3/envs/AI/lib/python3.8/site-packages (0.3.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytagcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cc12511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in /Users/sang-yun/anaconda3/envs/AI/lib/python3.8/site-packages (2.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90600c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: simplejson in /Users/sang-yun/anaconda3/envs/AI/lib/python3.8/site-packages (3.19.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install simplejson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "968a4daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.4.0 (SDL 2.26.4, Python 3.8.16)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pytagcloud\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d03de30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag = [(\"Hello\", 100), (\"World\", 80), (\"Python\",  200)]\n",
    "tag_list = pytagcloud.make_tags(tag, maxsize=50)  #태그가 큰 순서대로 이미지 크기 설정\n",
    "pytagcloud.create_tag_image(tag_list, \"./data/word_cloud.jpg\", size=(900,600), rectangular=False)\n",
    "webbrowser.open('word_cloud.jpg')  #웹 브라우저에서 이미지가 열린다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df414e8",
   "metadata": {},
   "source": [
    "## 문자열을 날짜로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5415da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4090aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_string = np.array(['03-04-2023 11:20 PM',\n",
    "                        '05-04-2023 09:20 PM',\n",
    "                        '07-04-2023 02:20 PM'\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724055b4",
   "metadata": {},
   "source": [
    "### Temp Stamp 객체로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92c692f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-03 23:20:00\n",
      "2023-04-05 21:20:00\n",
      "2023-04-07 14:20:00\n"
     ]
    }
   ],
   "source": [
    "for data in date_string :\n",
    "    #print(data)\n",
    "    temp = pd.to_datetime(data, format= '%d-%m-%Y %I:%M %p')\n",
    "    #print(temp)\n",
    "    \n",
    "for data in date_string :\n",
    "    temp_value = pd.to_datetime(data, format= '%d-%m-%Y %I:%M %p', errors='ignore')\n",
    "    print(temp_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d94e81",
   "metadata": {},
   "source": [
    "<h2 style=\"color: green;\">날짜 데이터 처리</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f257c3",
   "metadata": {},
   "source": [
    "## 시간대 데이터 처리 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c874275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-20 06:00:00\n"
     ]
    }
   ],
   "source": [
    "pd.Timestamp(\"2023-01-01 06:00:00\", tz=\"Europe/London\")\n",
    "data_temp = pd.Timestamp(\"2023-04-20 06:00:00\")\n",
    "print(data_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fafd8ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-20 06:00:00+01:00\n"
     ]
    }
   ],
   "source": [
    "#시간대를 지정\n",
    "date_in_london = data_temp.tz_localize(\"Europe/London\")\n",
    "print(date_in_london)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "511b0ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2023-02-28 00:00:00+00:00\n",
      "1   2023-03-31 00:00:00+00:00\n",
      "2   2023-04-30 00:00:00+00:00\n",
      "dtype: datetime64[ns, Africa/Abidjan]\n"
     ]
    }
   ],
   "source": [
    "#시간대를 변환\n",
    "date_in_london.tz_convert(\"Africa/Abidjan\")\n",
    "\n",
    "#세 개의 날짜를 만들기\n",
    "dates_temp = pd.Series(pd.date_range('2/2/2023', periods=3, freq='M'))\n",
    "temp = dates_temp.dt.tz_localize(\"Africa/Abidjan\")\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecc6e4c",
   "metadata": {},
   "source": [
    "## 시간대 데이터 처리 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c0fd2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['America/Maceio', 'America/Managua']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytz\n",
    "from pytz import all_timezones\n",
    "all_timezones[150:152]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f90dcb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2023-02-28 00:00:00+09:00\n",
       "1   2023-03-31 00:00:00+09:00\n",
       "2   2023-04-30 00:00:00+09:00\n",
       "dtype: datetime64[ns, tzfile('/usr/share/zoneinfo/Asia/Seoul')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_temp.dt.tz_localize(\"dateutil/Asia/Seoul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2e39483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2023-02-28 00:00:00+09:00\n",
      "1   2023-03-31 00:00:00+09:00\n",
      "2   2023-04-30 00:00:00+09:00\n",
      "dtype: datetime64[ns, Asia/Seoul]\n"
     ]
    }
   ],
   "source": [
    "tz_temp = pytz.timezone('Asia/Seoul')\n",
    "temp_01 = dates_temp.dt.tz_localize(tz_temp)\n",
    "print(temp_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecc93bf",
   "metadata": {},
   "source": [
    "## 날짜와 시간 선택하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d51f12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "                   date\n",
      "0   2023-01-01 00:00:00\n",
      "1   2023-01-01 01:00:00\n",
      "2   2023-01-01 02:00:00\n",
      "3   2023-01-01 03:00:00\n",
      "4   2023-01-01 04:00:00\n",
      "..                  ...\n",
      "995 2023-02-11 11:00:00\n",
      "996 2023-02-11 12:00:00\n",
      "997 2023-02-11 13:00:00\n",
      "998 2023-02-11 14:00:00\n",
      "999 2023-02-11 15:00:00\n",
      "\n",
      "[1000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.DataFrame()\n",
    "print(dataframe)\n",
    "dataframe['date'] = pd.date_range('1/1/2023', periods=1000, freq='H')\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca6b0296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   date\n",
      "date                                   \n",
      "2023-01-01 00:00:00 2023-01-01 00:00:00\n",
      "2023-01-01 01:00:00 2023-01-01 01:00:00\n",
      "2023-01-01 02:00:00 2023-01-01 02:00:00\n",
      "2023-01-01 03:00:00 2023-01-01 03:00:00\n",
      "2023-01-01 04:00:00 2023-01-01 04:00:00\n",
      "...                                 ...\n",
      "2023-02-11 11:00:00 2023-02-11 11:00:00\n",
      "2023-02-11 12:00:00 2023-02-11 12:00:00\n",
      "2023-02-11 13:00:00 2023-02-11 13:00:00\n",
      "2023-02-11 14:00:00 2023-02-11 14:00:00\n",
      "2023-02-11 15:00:00 2023-02-11 15:00:00\n",
      "\n",
      "[1000 rows x 1 columns]\n",
      "                                   date\n",
      "date                                   \n",
      "2023-01-01 01:00:00 2023-01-01 01:00:00\n",
      "2023-01-01 02:00:00 2023-01-01 02:00:00\n",
      "2023-01-01 03:00:00 2023-01-01 03:00:00\n",
      "2023-01-01 04:00:00 2023-01-01 04:00:00\n"
     ]
    }
   ],
   "source": [
    "#두 datetime 사이의 샘플을 선택합니다.\n",
    "dataframe[(dataframe['date'] > '2023-1-1 01:00:00') &\n",
    "          (dataframe['date'] <= '2023-1-1 04:00:00')]\n",
    "\n",
    "dataframe = dataframe.set_index(dataframe['date'])\n",
    "print(dataframe)\n",
    "\n",
    "temp02 = dataframe.loc['2023-1-1 01:00:00':'2023-1-1 04:00:00']\n",
    "print(temp02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e64e5e",
   "metadata": {},
   "source": [
    "## 날짜 데이터를 여러 특성으로 분할\n",
    "+ 날짜와 시간의 열로부터 년,월,일,시,분에 해당하는 특성을 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77db9930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  year  month  day  minute\n",
      "0 2023-01-01  2023      1    1       0\n",
      "1 2023-01-08  2023      1    8       0\n",
      "2 2023-01-15  2023      1   15       0\n",
      "3 2023-01-22  2023      1   22       0\n",
      "4 2023-01-29  2023      1   29       0\n"
     ]
    }
   ],
   "source": [
    "dateframe = pd.DataFrame()\n",
    "#5개의 날짜 만듬\n",
    "dateframe['date'] = pd.date_range('1/1/2023', periods=5, freq='W')\n",
    "#년, 월, 일, 시 , 분에 대한 특성을 만듭니다.\n",
    "dateframe['year'] = dateframe['date'].dt.year\n",
    "dateframe['month'] = dateframe['date'].dt.month\n",
    "dateframe['day'] = dateframe['date'].dt.day\n",
    "dateframe['minute'] = dateframe['date'].dt.minute\n",
    "                                  \n",
    "print(dateframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabf2767",
   "metadata": {},
   "source": [
    "## 날짜 간의 차이 계산\n",
    "+ 판다스의 TimeDelta 데이터 타입을 사용하면 두 지점 사이의 시간 변화를 기록한 특성을 계산합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93d2cfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2023-01-01\n",
      "1   2023-01-04\n",
      "Name: Arrived, dtype: datetime64[ns]\n",
      "0   2023-01-01\n",
      "1   2023-01-06\n",
      "Name: Left, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "date_frame = pd.DataFrame()\n",
    "\n",
    "date_frame['Arrived'] = [pd.Timestamp('01-01-2023'), pd.Timestamp('01-04-2023')]\n",
    "date_frame['Left'] = [pd.Timestamp('01-01-2023'), pd.Timestamp('01-06-2023')]\n",
    "\n",
    "print(date_frame['Arrived'])\n",
    "print(date_frame['Left'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "566bc34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#특성 사이의 차이를 계산\n",
    "date_frame['Left'] - date_frame['Arrived']\n",
    "\n",
    "pd.Series(delta.days for delta in (date_frame['Left'] - date_frame['Arrived']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73b75cf",
   "metadata": {},
   "source": [
    "## 시차 특성\n",
    "+ 판다스의 Shift를 사용하여 n기간만큼 차이가 나는 시차 특성을 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "737f12f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dates  stock_price  previous_Days_stock_price\n",
      "0 2023-01-01          1.1                        NaN\n",
      "1 2023-01-02          2.2                        NaN\n",
      "2 2023-01-03          3.3                        1.1\n",
      "3 2023-01-04          4.4                        2.2\n",
      "4 2023-01-05          5.5                        3.3\n"
     ]
    }
   ],
   "source": [
    "date_frame_temp = pd.DataFrame()\n",
    "\n",
    "#날짜 데이터 생성\n",
    "date_frame_temp['dates'] = pd.date_range('1/1/2023', periods=5, freq='D')\n",
    "date_frame_temp['stock_price'] = [1.1, 2.2, 3.3, 4.4, 5.5]\n",
    "\n",
    "date_frame_temp['previous_Days_stock_price'] = date_frame_temp['stock_price'].shift(2)\n",
    "print(date_frame_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ca3419",
   "metadata": {},
   "source": [
    "## 이동 시간 윈도 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d056ae21",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_index = pd.date_range('01-01-2023', periods=5, freq='M')\n",
    "\n",
    "date_frame01 = pd.DataFrame(index = time_index)\n",
    "date_frame01['Stock_price'] = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8de33c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Stock_price\n",
      "2023-01-31          NaN\n",
      "2023-02-28          1.5\n",
      "2023-03-31          2.5\n",
      "2023-04-30          3.5\n",
      "2023-05-31          4.5             Stock_price\n",
      "2023-01-31     1.000000\n",
      "2023-02-28     1.666667\n",
      "2023-03-31     2.428571\n",
      "2023-04-30     3.266667\n",
      "2023-05-31     4.161290\n"
     ]
    }
   ],
   "source": [
    "#이동 평균 계산\n",
    "a= date_frame01.rolling(window=2).mean()  #이동 평균을 계산\n",
    "b= date_frame01.ewm(alpha=0.5).mean()\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df194b02",
   "metadata": {},
   "source": [
    "## 시계열 데이터에서 누락된 값 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d968a7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [2023-01-31 00:00:00, 2023-02-28 00:00:00, 2023-03-31 00:00:00, 2023-04-30 00:00:00, 2023-05-31 00:00:00]\n"
     ]
    }
   ],
   "source": [
    "time_index = pd.date_range('01-01-2023', periods=5, freq='M')\n",
    "date_frame02 = pd.DataFrame(index=time_index)\n",
    "\n",
    "print(date_frame02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6e1e943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Sales\n",
      "2023-01-31    1.0\n",
      "2023-02-28    2.0\n",
      "2023-03-31    NaN\n",
      "2023-04-30    6.0\n",
      "2023-05-31    8.0\n"
     ]
    }
   ],
   "source": [
    "date_frame02['Sales'] = [1.0, 2.0, np.nan, np.nan, 8.0]  #누락값 있는 특성 생성\n",
    "\n",
    "date_frame02.interpolate()  #누락값 보간\n",
    "date_frame02.ffill()  #앞쪽으로 채우기\n",
    "date_frame02.bfill()  #뒤쪽으로 채우기\n",
    "date_frame02.interpolate(method='quadratic')  #비선형의 경우 보간 방법\n",
    "print(date_frame02.interpolate(limit=1, limit_direction='backward'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
